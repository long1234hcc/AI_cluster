{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "file_input_path = \"/content/tu_nhua_20_10_raw_AI.xlsx\"\n",
    "file_out_put = \"group_e_report.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.sparse import lil_matrix  # Import sparse matrix\n",
    "df = pd.read_excel(file_input_path)\n",
    "\n",
    "\n",
    "## Sử dụng dưới 100k dòng\n",
    "\n",
    "def normalized(txt):\n",
    "    cleaned_text = re.sub(r'[\\[\\(].*?[\\]\\)]\\s*', '', txt)\n",
    "    return str(cleaned_text).lower().strip()\n",
    "\n",
    "print(\"Read file\")\n",
    "# Load the updated data with text descriptions\n",
    "file_input_path = file_input_path  \n",
    "file_out_put = file_out_put  \n",
    "test_data = pd.read_excel(file_input_path)\n",
    "test_data[\"product_name\"] = test_data[\"product_name\"].apply(normalized)\n",
    "# test_data = test_data.iloc[0:1000]\n",
    "print(\"Load model\")\n",
    "\n",
    "# Initialize the tokenizer and model for inflat-e5-large-v2\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"intfloat/multilingual-e5-large\")\n",
    "model = AutoModel.from_pretrained(\"intfloat/multilingual-e5-large\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts):\n",
    "        self.texts = texts\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.texts[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tokenizer(batch, return_tensors='pt', padding=True, truncation=True, max_length=300)\n",
    "\n",
    "def preprocess_texts(dataloader, model, device):\n",
    "    model.eval()\n",
    "    features = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc='Processing Batches'):\n",
    "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**inputs)\n",
    "            embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "            features.append(embeddings)\n",
    "\n",
    "    return np.concatenate(features, axis=0)\n",
    "\n",
    "# Extract features\n",
    "print(\"Embedding...\")\n",
    "texts = test_data[\"product_name\"].tolist()\n",
    "dataset = TextDataset(texts)\n",
    "dataloader = DataLoader(dataset, batch_size=32, collate_fn=collate_fn)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "features = preprocess_texts(dataloader, model, device)\n",
    "\n",
    "# Optionally, reduce dimensionality with PCA\n",
    "pca = PCA(n_components=300)\n",
    "features_reduced = pca.fit_transform(features)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "features_standardized = scaler.fit_transform(features_reduced)\n",
    "\n",
    "# Group similar vectors using cosine similarity with sparse matrix\n",
    "def group_similar_vectors_cosine_sparse(all_embeddings, threshold=0.75, batch_size=1000):\n",
    "    embeddings = torch.tensor(all_embeddings, dtype=torch.float32)\n",
    "    embedding_count = len(all_embeddings)\n",
    "    similarity_matrix = lil_matrix((embedding_count, embedding_count))\n",
    "    print(similarity_matrix.shape)\n",
    "\n",
    "    # Compute similarity matrix in batches\n",
    "    for i in tqdm(range(0, embedding_count, batch_size), desc='Computing Similarity Matrix'):\n",
    "        for j in range(0, embedding_count, batch_size):\n",
    "            batch_embeddings_i = embeddings[i:i + batch_size]\n",
    "            batch_embeddings_j = embeddings[j:j + batch_size]\n",
    "            similarity = F.cosine_similarity(batch_embeddings_i.unsqueeze(1), batch_embeddings_j.unsqueeze(0), dim=-1)\n",
    "            similarity = similarity.numpy()\n",
    "            for m in range(similarity.shape[0]):\n",
    "                for n in range(similarity.shape[1]):\n",
    "                    if similarity[m, n] >= threshold:\n",
    "                        similarity_matrix[i + m, j + n] = similarity[m, n]\n",
    "\n",
    "    group_ids = [-1] * embedding_count\n",
    "    current_group_id = 0\n",
    "\n",
    "    for i in tqdm(range(embedding_count), desc='Grouping Vectors'):\n",
    "        if group_ids[i] == -1:\n",
    "            group_ids[i] = current_group_id\n",
    "            for j in range(i + 1, embedding_count):\n",
    "                if group_ids[j] == -1 and similarity_matrix[i, j] >= threshold:\n",
    "                    group_ids[j] = current_group_id\n",
    "            current_group_id += 1\n",
    "\n",
    "    return group_ids\n",
    "\n",
    "# Use the sparse matrix-based cosine similarity grouping function\n",
    "group_ids = group_similar_vectors_cosine_sparse(features_standardized, threshold=0.75, batch_size=1000)\n",
    "\n",
    "# Create a new DataFrame to store results\n",
    "result_df = test_data.copy()\n",
    "result_df['group_text'] = group_ids\n",
    "\n",
    "# Save to Excel\n",
    "result_df.to_excel(file_out_put, index=False)\n",
    "\n",
    "print(\"Finished processing and saved results to\", file_out_put)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
